{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "929aef20-8f55-438e-9156-7362b8490091",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Naïve bayes-1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c1a156-8b22-4583-be33-156c15f2dc27",
   "metadata": {},
   "source": [
    "#### Q1. What is Bayes' theorem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd6ec82-d36f-40a5-b929-ab91cc68a249",
   "metadata": {},
   "source": [
    "Bayes' theorem is a fundamental concept in probability theory and statistics that describes how to update our beliefs or knowledge about an event based on new evidence or information. It provides a way to calculate the probability of an event happening given the probabilities of related events."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b312036-afdc-4389-9c35-53cf4023690e",
   "metadata": {},
   "source": [
    "#### Q2. What is the formula for Bayes' theorem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0305ac-9d98-4945-a052-f7e54fb0348f",
   "metadata": {},
   "source": [
    "The formula for Bayes' theorem is as follows:\n",
    "**P(A∣B)= (P(B∣A)⋅P(A)) / P(B)**\n",
    "\n",
    "Where:\n",
    "* P(A∣B) is the posterior probability of event A occurring given event B has occurred.\n",
    "* P(B∣A) is the likelihood of event B occurring given event A has occurred.\n",
    "* P(A) is the prior probability of event A occurring.\n",
    "* P(B) is the probability of event B occurring."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c61482c-9d0e-4bfd-8786-3f31af1ca83b",
   "metadata": {},
   "source": [
    "#### Q3. How is Bayes' theorem used in practice?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84575e66-b451-45c2-9a2a-879fa49016ab",
   "metadata": {},
   "source": [
    "Bayes' theorem is used to update the probability of a hypothesis as new evidence is obtained. It is widely used in various fields, including:\n",
    "* **Statistics:** In Bayesian statistics, it's used to update beliefs about parameters or models based on observed data.\n",
    "* **Machine Learning:** Bayesian methods are used for probabilistic modeling, parameter estimation, and making predictions.\n",
    "* **Medical Diagnosis:** Bayes' theorem helps in updating the probability of a disease given the presence of certain symptoms.\n",
    "* **Spam Filtering:** Email services use Bayes' theorem to classify emails as spam or not based on the occurrence of certain words.\n",
    "* **Natural Language Processing:** It's used in tasks like language modeling and part-of-speech tagging."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306a12f8-35b6-46f2-b0f3-7f43c3f526b9",
   "metadata": {},
   "source": [
    "#### Q4. What is the relationship between Bayes' theorem and conditional probability?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c260a4cd-0cdb-4bad-8776-cf01320dd39f",
   "metadata": {},
   "source": [
    "Bayes' theorem is derived from conditional probability. The formula for conditional probability P(A∣B) can be rearranged using the definition of joint probability and the definition of conditional probability, which leads to Bayes' theorem.\n",
    "**P(A∣B) = P(A∩B)/P(B) = (P(B∣A)⋅P(A)) / P(B)**\n",
    "\n",
    "So, Bayes' theorem is an application of conditional probability, providing a systematic way to update probabilities based on new information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b1b173-4c9a-43bb-9660-8216f8d54afe",
   "metadata": {},
   "source": [
    "#### Q5. How do you choose which type of Naive Bayes classifier to use for any given problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da0447d-937c-487d-af93-6a45bb23f8ff",
   "metadata": {},
   "source": [
    "There are different variants of the Naive Bayes classifier, such as Gaussian Naive Bayes, Multinomial Naive Bayes, and Bernoulli Naive Bayes. The choice depends on the nature of your data and the problem you're trying to solve:\n",
    "* **Gaussian Naive Bayes:** This is used when the features have a continuous distribution, and their values can be modeled using a Gaussian (normal) distribution.\n",
    "* **Multinomial Naive Bayes:** It's suitable for problems involving discrete data, such as text classification where the features are word counts or frequencies.\n",
    "* **Bernoulli Naive Bayes:** This is used when the features are binary (yes/no) or represent the presence/absence of certain features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564f5247-04bf-4d22-8352-7478ecf4d980",
   "metadata": {},
   "source": [
    "#### Q6. Assignment:\n",
    "You have a dataset with two features, X1 and X2, and two possible classes, A and B. You want to use Naive\n",
    "Bayes to classify a new instance with features X1 = 3 and X2 = 4. The following table shows the frequency of\n",
    "each feature value for each class:\n",
    "* Table:\n",
    "    * Class X1=1 X1=2 X1=3 X2=1 X2=2 X2=3 X2=4\n",
    "    * A      3 3 4 4 3 3 3\n",
    "    * B 2 2 1 2 2 2 3\n",
    "* Assuming equal prior probabilities for each class, which class would Naive Bayes predict the new instance to belong to?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70419eb0-8751-4f1d-bc75-280ab391e514",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Naive Bayes classifier predicts that the new instance belongs to Class A\n"
     ]
    }
   ],
   "source": [
    "# Define the data\n",
    "data = {\n",
    "    'X1=1': {'A': 3, 'B': 2},\n",
    "    'X1=2': {'A': 3, 'B': 2},\n",
    "    'X1=3': {'A': 4, 'B': 1},\n",
    "    'X2=1': {'A': 4, 'B': 2},\n",
    "    'X2=2': {'A': 3, 'B': 2},\n",
    "    'X2=3': {'A': 3, 'B': 2},\n",
    "    'X2=4': {'A': 3, 'B': 3}\n",
    "}\n",
    "\n",
    "# Prior probabilities\n",
    "prior_A = 0.5\n",
    "prior_B = 0.5\n",
    "\n",
    "# New instance features\n",
    "X1 = 3\n",
    "X2 = 4\n",
    "\n",
    "# Calculate the posterior probabilities for classes A and B\n",
    "posterior_A = prior_A\n",
    "posterior_B = prior_B\n",
    "\n",
    "for feature in ['X1', 'X2']:\n",
    "    value = globals()[feature]\n",
    "    key = f\"{feature}={value}\"\n",
    "    posterior_A *= data[key]['A'] / sum(data[key].values())\n",
    "    posterior_B *= data[key]['B'] / sum(data[key].values())\n",
    "\n",
    "# Make the prediction\n",
    "predicted_class = 'A' if posterior_A > posterior_B else 'B'\n",
    "\n",
    "print(f\"The Naive Bayes classifier predicts that the new instance belongs to Class {predicted_class}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
