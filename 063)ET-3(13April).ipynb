{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "008e348b-9e3a-4aa7-9624-b263b4a23e4b",
   "metadata": {},
   "source": [
    "# Ensemble Techniques And Its Types-3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45bdd4a9-44b6-462a-a7ff-31348e4f1f51",
   "metadata": {},
   "source": [
    "#### Q1. What is Random Forest Regressor?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4153b153-4acd-42e1-82e3-8efc20d2f931",
   "metadata": {},
   "source": [
    "Random Forest Regressor is an ensemble machine learning algorithm that is used for regression tasks. It is an extension of the Random Forest algorithm, which combines the predictions of multiple decision trees to make accurate and robust predictions of numeric (continuous) target variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa20a61a-50c7-4510-badc-3051116d955d",
   "metadata": {},
   "source": [
    "#### Q2. How does Random Forest Regressor reduce the risk of overfitting?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ec44b9-eb28-4b2e-856f-401a030c0f9c",
   "metadata": {},
   "source": [
    "Random Forest Regressor reduces the risk of overfitting through two main mechanisms:\n",
    "* **Bootstrapping:** Each decision tree in the Random Forest is trained on a bootstrapped (randomly sampled with replacement) subset of the training data. This introduces diversity among the trees and prevents them from fitting noise in the data.\n",
    "* **Feature Randomization:** Random Forest also randomly selects a subset of features to consider when making splits at each node of the decision tree. This feature selection randomness further reduces overfitting by avoiding reliance on a specific subset of features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3998b18c-0c9b-47ac-85ba-3e916cc012cc",
   "metadata": {},
   "source": [
    "#### Q3. How does Random Forest Regressor aggregate the predictions of multiple decision trees?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937a3855-4482-47d9-8f8c-a2a4076719af",
   "metadata": {},
   "source": [
    "Random Forest Regressor aggregates the predictions of multiple decision trees by taking the average (mean) of their predictions. For a given input sample, each tree in the ensemble produces a prediction, and the final prediction is the average of these individual predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bbee82-7bfb-44e1-80bc-5009c7103b73",
   "metadata": {},
   "source": [
    "#### Q4. What are the hyperparameters of Random Forest Regressor?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b09e53-bda9-451b-9fe8-709dac8ce41c",
   "metadata": {},
   "source": [
    "Common hyperparameters of Random Forest Regressor include:\n",
    "* **n_estimators:** The number of decision trees in the ensemble.\n",
    "* **max_depth:** The maximum depth of each decision tree.\n",
    "* **min_samples_split:** The minimum number of samples required to split an internal node.\n",
    "* **min_samples_leaf:** The minimum number of samples required to be in a leaf node.\n",
    "* **max_features:** The number of features to consider when making splits.\n",
    "* **random_state:** A seed for the random number generator for reproducibility.\n",
    "\n",
    "*Other hyperparameters related to bootstrapping and feature randomization.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898f9284-7b2b-4d5b-b98f-bb43326900e1",
   "metadata": {},
   "source": [
    "#### Q5. What is the difference between Random Forest Regressor and Decision Tree Regressor?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055a7135-62d9-4a4f-9a62-344c83d70882",
   "metadata": {},
   "source": [
    "The main differences are:\n",
    "* Random Forest Regressor is an ensemble method that combines multiple decision trees, whereas Decision Tree Regressor is a single decision tree.\n",
    "* Random Forest Regressor reduces overfitting and generalizes better compared to a single Decision Tree Regressor.\n",
    "* Random Forest Regressor provides more robust and accurate predictions, especially when dealing with complex datasets or noisy data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422e287c-f09c-440a-96fd-83529c78cfe2",
   "metadata": {},
   "source": [
    "#### Q6. What are the advantages and disadvantages of Random Forest Regressor?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e463136f-2cbc-4423-ab80-d05af48728c1",
   "metadata": {},
   "source": [
    "* **Advantages:**\n",
    "    * High predictive accuracy.\n",
    "    * Reduced risk of overfitting.\n",
    "    * Robust to noisy data.\n",
    "    * Can handle both numerical and categorical features.\n",
    "    * Provides feature importances for feature selection.\n",
    "* **Disadvantages:**\n",
    "    * Complexity and computational resources required may be higher than simpler models.\n",
    "    * Less interpretable compared to a single decision tree.\n",
    "    * May not perform as well as deep learning models on certain tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edb32f4-1788-4a10-a0f6-0e9c34e14698",
   "metadata": {},
   "source": [
    "#### Q7. What is the output of Random Forest Regressor?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6786f0-526d-436d-a21d-e00e9a37327b",
   "metadata": {},
   "source": [
    "The output of a Random Forest Regressor is a continuous numeric value, which represents the predicted value for a given input sample."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41d8ec6-4957-4ad3-9044-5ed9df46c63e",
   "metadata": {},
   "source": [
    "#### Q8. Can Random Forest Regressor be used for classification tasks?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8b921a-19c3-4566-9c99-8709efe68f7e",
   "metadata": {},
   "source": [
    "No, Random Forest Regressor is specifically designed for regression tasks, where the goal is to predict continuous numeric values. For classification tasks, you would typically use Random Forest Classifier or another classification algorithm."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
