{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc8e435e-fd72-4d88-9bd2-8424425a091c",
   "metadata": {},
   "source": [
    "# Dimensionality Reduction-3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a14a6ed-3726-4e53-8367-8ff936f20299",
   "metadata": {},
   "source": [
    "#### Q1. What are Eigenvalues and Eigenvectors? How are they related to the Eigen-Decomposition approach? Explain with an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4fbc314-fec1-4b85-8ba9-0c0109fb4744",
   "metadata": {},
   "source": [
    "Eigenvalues and eigenvectors are concepts in linear algebra that are closely related to the eigen-decomposition approach. In the eigen-decomposition of a square matrix, such as A, er seek to decompose it into the product of three matrices: P, Λ, and P⁻¹, where P is a matrix consisting of eigenvectors, Λ is a diagonal matrix consisting of eigenvalues, and P⁻¹ is the inverse of the matrix P. The relationship is represented as: **A = PΛP⁻¹**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b75f6df-975f-420c-9498-9b4ece863a3f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eigenvalues:\n",
      "[3. 2.]\n",
      "\n",
      "Eigenvectors:\n",
      "[[ 1.         -0.70710678]\n",
      " [ 0.          0.70710678]]\n"
     ]
    }
   ],
   "source": [
    "# To perform eigen-decomposition, we find the eigenvalues (λ) and eigenvectors (v) of A\n",
    "import numpy as ny\n",
    "# Create a sample square matrix\n",
    "A = ny.array([[3, 1],\n",
    "              [0, 2]])\n",
    "\n",
    "# Calculate eigenvalues and eigenvectors using NumPy\n",
    "eigenvalues, eigenvectors = ny.linalg.eig(A)\n",
    "\n",
    "# Print eigenvalues and eigenvectors\n",
    "print(\"Eigenvalues:\")\n",
    "print(eigenvalues)\n",
    "print(\"\\nEigenvectors:\")\n",
    "print(eigenvectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d015fa49-9737-4081-b86c-3bfae89466be",
   "metadata": {},
   "source": [
    "#### Q2. What is eigen decomposition and what is its significance in linear algebra?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d61a2a-96d0-43dd-a0db-f5d28556ceb6",
   "metadata": {},
   "source": [
    "Eigen decomposition is a fundamental concept in linear algebra. It is the process of decomposing a square matrix into a set of its eigenvalues and eigenvectors, as described in the previous answer. Eigen decomposition is significant because it can help analyze and understand the properties of a matrix, simplify mathematical operations involving the matrix, and solve linear differential equations efficiently."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e528789-0917-4c93-b5e6-b32e6dd3cf0a",
   "metadata": {},
   "source": [
    "#### Q3. What are the conditions that must be satisfied for a square matrix to be diagonalizable using the Eigen-Decomposition approach? Provide a brief proof to support your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8c7e15-4b20-4999-a3a9-ccb574ccc3fb",
   "metadata": {},
   "source": [
    "For a square matrix to be diagonalizable using the eigen-decomposition approach, it must satisfy the following conditions:\n",
    "* The matrix must be square, meaning it has an equal number of rows and columns.\n",
    "* The matrix must have a full set of linearly independent eigenvectors. \n",
    "* In other words, the number of linearly independent eigenvectors must equal the matrix's size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b19ff81-7d17-4efe-84ec-96a8d53c5111",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix A is not diagonalizable.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Let A be a square matrix of size nxn. To check for diagonalizability,we need to find n linearly independent eigenvectors.\n",
    "If A has n linearly independent eigenvectors, it means it can be diagonalized.\n",
    "'''\n",
    "import numpy as ny\n",
    "\n",
    "# Create a sample square matrix\n",
    "A = ny.array([[3, 1],\n",
    "              [0, 2]])\n",
    "\n",
    "# Check if A is diagonalizable\n",
    "is_diagonalizable = ny.all(ny.linalg.eigvals(A) == ny.linalg.eigvals(A.T))\n",
    "\n",
    "# Print the result\n",
    "if is_diagonalizable:\n",
    "    print(\"Matrix A is diagonalizable.\")\n",
    "else:\n",
    "    print(\"Matrix A is not diagonalizable.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6aa7d5-d967-4d3a-a2b0-b32d41385de2",
   "metadata": {},
   "source": [
    "#### Q4. What is the significance of the spectral theorem in the context of the Eigen-Decomposition approach? How is it related to the diagonalizability of a matrix? Explain with an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a9e4d7-f346-4598-a4b2-ef71a16c0999",
   "metadata": {},
   "source": [
    "The spectral theorem is a fundamental result in linear algebra that is closely related to the eigen-decomposition of symmetric matrices. It states that for any real symmetric matrix, all of its eigenvalues are real, and its eigenvectors are orthogonal (perpendicular) to each other.\n",
    "\n",
    "The spectral theorem is significant because it guarantees the existence of a complete set of real eigenvalues and orthogonal eigenvectors for symmetric matrices. This property is crucial in the context of eigen-decomposition because it simplifies the diagonalization process for symmetric matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4bd5a2b-de11-4857-b4fa-e33604d22f5c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix A satisfies the conditions of the spectral theorem.\n"
     ]
    }
   ],
   "source": [
    "# Example: Suppose we have a symmetric matrix A:\n",
    "import numpy as ny\n",
    "\n",
    "# Create a symmetric matrix\n",
    "A = ny.array([[4, 2],\n",
    "              [2, 5]])\n",
    "\n",
    "# Calculate eigenvalues and eigenvectors using NumPy\n",
    "eigenvalues, eigenvectors = ny.linalg.eig(A)\n",
    "\n",
    "# Check if all eigenvalues are real and eigenvectors are orthogonal\n",
    "is_symmetric = ny.all(ny.isreal(eigenvalues))\n",
    "is_orthogonal = ny.allclose(ny.dot(eigenvectors, eigenvectors.T), ny.eye(len(eigenvectors)))\n",
    "\n",
    "# Print the results\n",
    "if is_symmetric and is_orthogonal:\n",
    "    print(\"Matrix A satisfies the conditions of the spectral theorem.\")\n",
    "else:\n",
    "    print(\"Matrix A does not satisfy the conditions of the spectral theorem.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0d2682-1a1f-4ea1-976e-af98ee928b3b",
   "metadata": {},
   "source": [
    "#### Q5. How do you find the eigenvalues of a matrix and what do they represent?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09eb6779-3e88-4cba-b9e7-7e8b1c6a7424",
   "metadata": {},
   "source": [
    "To find the eigenvalues of a square matrix A, we solve the characteristic equation, which is given by:\n",
    "**|A - λI| = 0**\n",
    "\n",
    "*Where A is the matrix, λ represents the eigenvalue we want to find, and I is the identity matrix.*\n",
    "\n",
    "Solving this equation for λ yields the eigenvalues of the matrix. Eigenvalues represent the scaling factors by which eigenvectors are stretched or compressed when multiplied by the matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24dccd1-0a9c-4714-b49b-6a85d326ee08",
   "metadata": {},
   "source": [
    "#### Q6. What are eigenvectors and how are they related to eigenvalues?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7318136f-eef4-448a-9169-2f5cd550900c",
   "metadata": {},
   "source": [
    "Eigenvectors are vectors associated with eigenvalues in the context of a square matrix A. An eigenvector v and its corresponding eigenvalue λ satisfy the equation (A - λI)v = 0. Eigenvectors represent directions in space that remain unchanged in direction (only scaled) when the matrix A is applied to them. They are essential in understanding the behavior of linear transformations and diagonalizing matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e98879-8db8-446b-9dae-a2794b1a52b7",
   "metadata": {},
   "source": [
    "#### Q7. Can you explain the geometric interpretation of eigenvectors and eigenvalues?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24ab326-6018-4928-a83e-b4775150c48c",
   "metadata": {},
   "source": [
    "The geometric interpretation of eigenvectors and eigenvalues is as follows:\n",
    "* Eigenvectors represent directions in space that remain unchanged when a linear transformation (represented by the matrix A) is applied. They are vectors that may only be stretched or compressed (scaled) but not rotated by the transformation.\n",
    "* Eigenvalues represent the scaling factors by which the eigenvectors are stretched or compressed during the transformation. If an eigenvalue is 1, it indicates that the corresponding eigenvector is not stretched or compressed at all.\n",
    "\n",
    "In geometric terms, eigenvectors and eigenvalues provide insights into the fundamental directions and magnitudes of change in a linear transformation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f064f74a-3d87-4289-ae7b-2ecf775452fb",
   "metadata": {},
   "source": [
    "#### Q8. What are some real-world applications of eigen decomposition?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db52b61b-7671-4fb9-bf97-b5940269cfb1",
   "metadata": {},
   "source": [
    "Eigen decomposition has numerous real-world applications, including:\n",
    "* **Principal Component Analysis (PCA):** Used for dimensionality reduction and feature extraction in data analysis and machine learning.\n",
    "* **Vibrational analysis:** Used to study the vibrational modes of complex molecules in chemistry.\n",
    "* **Quantum mechanics:** Used to find energy levels and wavefunctions of quantum systems.\n",
    "* **Image compression:** Used to compress images by representing them in a more compact form.\n",
    "* **Structural engineering:** Used for modal analysis to study the dynamic behavior of structures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779a2bf3-96f6-4a85-8e5f-d11dad644d06",
   "metadata": {},
   "source": [
    "#### Q9. Can a matrix have more than one set of eigenvectors and eigenvalues?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13756d79-b6c3-499f-bd6a-38573a4c7355",
   "metadata": {},
   "source": [
    "A matrix can have more than one set of eigenvectors and eigenvalues if it is not diagonalizable. However, when we talk about diagonalizability, we usually refer to matrices that have a full set of linearly independent eigenvectors. In this case, there is a unique set of eigenvalues and eigenvectors that diagonalize the matrix. If a matrix is diagonalizable, it can still have multiple eigenvectors associated with the same eigenvalue, as long as they are linearly independent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8feabe-6dfa-48f7-b620-de74ade5793c",
   "metadata": {},
   "source": [
    "#### Q10. In what ways is the Eigen-Decomposition approach useful in data analysis and machine learning? Discuss at least three specific applications or techniques that rely on Eigen-Decomposition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b812ea1d-e71a-480c-9455-7582aca041e3",
   "metadata": {},
   "source": [
    "The Eigen-Decomposition approach is useful in data analysis and machine learning in various ways:\n",
    "* **Principal Component Analysis (PCA):** PCA uses eigen-decomposition to find the principal components of a dataset, which are linear combinations of the original features. It is widely used for dimensionality reduction and feature extraction in data preprocessing.\n",
    "* **Spectral Clustering:** Eigen-decomposition is applied to the similarity matrix in spectral clustering algorithms. It helps partition data into clusters by analyzing the eigenvalues and eigenvectors of the matrix.\n",
    "* **Recommender Systems:** Eigen-decomposition is used in collaborative filtering methods like Singular Value Decomposition (SVD) to make recommendations by factorizing user-item interaction matrices.\n",
    "\n",
    "These applications demonstrate how eigen-decomposition plays a crucial role in extracting valuable information from data, reducing dimensionality, and solving various machine learning problems."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
