{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0363711f-543e-44ed-a3ec-4d2d80f4545d",
   "metadata": {},
   "source": [
    "# Support Vector Machines-2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd75bfc3-e89b-4ae6-b230-1766d697f5c4",
   "metadata": {},
   "source": [
    "#### Q1. What is the relationship between polynomial functions and kernel functions in machine learning algorithms?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4bd950-74d2-4be4-8185-7b8041ea235e",
   "metadata": {},
   "source": [
    " The relationship between polynomial functions and kernel functions in machine learning algorithms lies in the concept of the \"kernel trick.\" A polynomial kernel is a specific type of kernel function used in Support Vector Machines (SVM) and other machine learning algorithms. Kernel functions allow us to implicitly perform computations in a higher-dimensional feature space without actually transforming the data into that space.\n",
    "\n",
    "Polynomial kernel functions are a type of kernel that computes the inner product of transformed data points in a higher-dimensional space, where the transformation is defined by a polynomial function. This allows SVM to effectively learn non-linear decision boundaries in the original feature space by mapping the data into a higher-dimensional space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a265094-7de0-4df0-9fe8-ba29c2f1e315",
   "metadata": {},
   "source": [
    "#### Q2. How can we implement an SVM with a polynomial kernel in Python using Scikit-learn?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd410fea-1c59-41d7-95f6-6493fdd5eb4c",
   "metadata": {},
   "source": [
    "To implement an SVM with a polynomial kernel in Python using Scikit-learn, we can use the SVC class and specify the kernel parameter as 'poly'. We can also set the degree parameter to control the degree of the polynomial. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99a90f3e-cc67-4da6-94ff-4436a2a61287",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Here's an example:\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train SVM with polynomial kernel\n",
    "svm_poly = SVC(kernel='poly', degree=3)\n",
    "svm_poly.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = svm_poly.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fa9568-af19-47da-8ff0-3e8ae91e906a",
   "metadata": {},
   "source": [
    "#### Q3. How does increasing the value of epsilon affect the number of support vectors in SVR?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a1bdbb-72fa-4332-a623-822c8f333031",
   "metadata": {},
   "source": [
    "In Support Vector Regression (SVR), the epsilon parameter (often denoted as ε) is used to define the margin of tolerance for errors in the regression prediction. It determines the width of the ε-tube around the predicted regression line where data points are considered to be within an acceptable error range. Increasing the value of epsilon allows more data points to be within the ε-tube and potentially become support vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbc5b48-963b-4bd0-9de6-8595c36ac47e",
   "metadata": {},
   "source": [
    "#### Q4. How does the choice of kernel function, C parameter, epsilon parameter, and gamma parameter affect the performance of Support Vector Regression (SVR)? Can you explain how each parameter works and provide examples of when you might want to increase or decrease its value?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc6638c-4607-481a-b42e-08e78d9209a2",
   "metadata": {},
   "source": [
    "The performance of Support Vector Regression (SVR) is influenced by various parameters:\n",
    "* **Kernel Function:** The choice of kernel function (linear, polynomial, radial basis function, etc.) defines the transformation used to map the data into a higher-dimensional space. The appropriate kernel depends on the data's distribution and the complexity of the underlying relationship.\n",
    "* **C Parameter:** The C parameter trades off between finding a larger-margin hyperplane and a lower training error. Smaller values of C create a wider margin but might tolerate more errors, while larger values of C create a narrower margin but aim to minimize errors.\n",
    "* **Epsilon Parameter:** As mentioned earlier, the epsilon parameter defines the width of the ε-tube in SVR. A larger epsilon allows more data points within the tube, potentially resulting in a larger number of support vectors.\n",
    "* **Gamma Parameter:** For non-linear kernels like RBF, the gamma parameter defines the influence of a single training example. Higher values of gamma lead to more complex decision boundaries and can cause overfitting if not properly tuned.\n",
    "\n",
    "For example, increasing the C parameter might be useful when the dataset has noisy or overlapping points, while tuning the epsilon parameter might be necessary to control the trade-off between fitting the data closely and generalizing well to new data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76f7df3-fc78-47c8-9872-d80332bbbcd7",
   "metadata": {},
   "source": [
    "#### Q5. Assignment:\n",
    "* Import the necessary libraries and load the dataseg\n",
    "* Split the dataset into training and testing setZ\n",
    "* Preprocess the data using any technique of your choice (e.g. scaling, normaliMationK\n",
    "* Create an instance of the SVC classifier and train it on the training datW\n",
    "* hse the trained classifier to predict the labels of the testing datW\n",
    "* Evaluate the performance of the classifier using any metric of your choice (e.g. accuracy, precision, recall, F1-score\n",
    "* Tune the hyperparameters of the SVC classifier using GridSearchCV or RandomiMedSearchCV to improve its performanc_\n",
    "* Train the tuned classifier on the entire dataseg\n",
    "* Save the trained classifier to a file for future use.\n",
    "\n",
    "**Note:** You can use any dataset of your choice for this assignment, but make sure it is suitable for\n",
    "classification and has a sufficient number of features and samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4a9c9e5-7d5f-49e0-89ff-00d1a0017491",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from joblib import dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0789408-6310-4e5e-a0ac-a8478b1c7ba9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['tuned_svc_classifier.joblib']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the Dataset and spliting them\n",
    "ds = load_wine()\n",
    "x=ds.data[:, :2]\n",
    "y=ds.target\n",
    "X_train,X_test,y_train,y_test = train_test_split(x,y,test_size=0.10,random_state=27, stratify =y)\n",
    "\n",
    "# Scaling the X dataset\n",
    "ss = StandardScaler()\n",
    "x_train = ss.fit_transform(X_train)\n",
    "x_test = ss.transform(X_test)\n",
    "\n",
    "# Model Training\n",
    "model = SVC()\n",
    "model.fit(x_train,y_train)\n",
    "\n",
    "# Prediction & Evaluaation\n",
    "y_pred = model.predict(x_test)\n",
    "acc = accuracy_score(y_test,y_pred)\n",
    "print(f\"Accuracy: {acc:.1f}\")\n",
    "\n",
    "# Tune hyperparameters using GridSearchCV\n",
    "param_grid = {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf', 'poly'], 'gamma': ['scale', 'auto']}\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5)\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Get the best tuned classifier\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Train the tuned classifier on the entire dataset\n",
    "best_model.fit(x_train, y_train)\n",
    "\n",
    "# Save the trained classifier to a file\n",
    "dump(best_model, 'tuned_svc_classifier.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2f12fa-68e3-4d6f-bdd2-9c1a6d1ecf63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
