{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4548d88d-4932-46bb-9afd-56278a172cc8",
   "metadata": {},
   "source": [
    "# Regression-4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca80a43a-8a70-4df5-aee1-c678eeb546f4",
   "metadata": {},
   "source": [
    "#### Q1. What is Lasso Regression, and how does it differ from other regression techniques?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6afb5a-157f-46ba-a8ab-d962a8fda619",
   "metadata": {},
   "source": [
    "**Lasso Regression (Lasso stands for Least Absolute Shrinkage and Selection Operator)** is a type of linear regression that adds an L1 regularization term to the least squares cost function. This L1 penalty encourages some coefficients to become exactly zero, effectively performing feature selection. Lasso differs from other regression techniques like Ridge and ordinary least squares by its emphasis on sparsity and the ability to select relevant features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fad30b-3571-4634-bbea-85cca28e8b94",
   "metadata": {},
   "source": [
    "#### Q2. What is the main advantage of using Lasso Regression in feature selection?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1365e4-21e2-457e-b4d9-305f6015e6ae",
   "metadata": {},
   "source": [
    "The main advantage of Lasso Regression for feature selection is that it can lead to sparse models by setting some coefficients to exactly zero. This means it can automatically identify and include only the most important predictors in the model, thus simplifying the model and improving its interpretability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13cf786a-5220-4472-8ddc-c3ab8f0a801b",
   "metadata": {},
   "source": [
    "#### Q3. How do you interpret the coefficients of a Lasso Regression model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620475e9-4b82-4c71-938f-eaef3174b449",
   "metadata": {},
   "source": [
    "Interpreting coefficients in Lasso Regression is similar to other regression techniques. Each coefficient represents the change in the dependent variable for a unit change in the corresponding independent variable, while keeping other variables constant. However, due to the L1 regularization, some coefficients might be exactly zero, indicating that the corresponding feature is not contributing to the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a20b281-bee1-477d-b97e-d09f53365c44",
   "metadata": {},
   "source": [
    "#### Q4. What are the tuning parameters that can be adjusted in Lasso Regression, and how do they affect the model's performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52fb77be-9326-4b51-bf66-10706b10c090",
   "metadata": {},
   "source": [
    "The main tuning parameter in Lasso Regression is the regularization parameter (lambda or alpha). It controls the strength of the regularization penalty. Larger values of lambda lead to stronger regularization, resulting in more coefficients being pushed towards zero. Smaller values of lambda reduce the amount of regularization, allowing coefficients to take larger values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e56efd-0fbd-43ac-837c-fd0af7cb7404",
   "metadata": {},
   "source": [
    "#### Q5. Can Lasso Regression be used for non-linear regression problems? If yes, how?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6a53c5-84f2-4f73-999b-bffef25dd036",
   "metadata": {},
   "source": [
    "Lasso Regression is inherently a linear method, and it's most suitable for linear problems. However, we can extend Lasso to handle non-linear problems by applying feature transformations, such as polynomial features or using basis functions, before using Lasso. For more complex non-linear problems, other techniques like kernel methods or non-linear models might be more appropriate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de834e1-d386-428b-8453-1d2ac1ecb581",
   "metadata": {},
   "source": [
    "#### Q6. What is the difference between Ridge Regression and Lasso Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572d0cd7-2fab-4697-aaef-700a03a2154b",
   "metadata": {},
   "source": [
    "* Ridge adds an L2 penalty (squared coefficients) to the cost function, which doesn't set coefficients to exactly zero. Lasso adds an L1 penalty, which can result in exact zeros and thus performs feature selection.\n",
    "* Lasso is more suitable for situations with many irrelevant features, as it can remove them completely.\n",
    "* Ridge tends to shrink coefficients towards zero without making them exactly zero, while Lasso can lead to some coefficients being exactly zero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8ffba0-e07b-486f-941c-6084fffca9ce",
   "metadata": {},
   "source": [
    "#### Q7. Can Lasso Regression handle multicollinearity in the input features? If yes, how?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4aae7b-3227-4e10-b38e-d62959ac72f8",
   "metadata": {},
   "source": [
    "Lasso Regression can handle multicollinearity by shrinking coefficients towards zero, effectively reducing the impact of correlated features. In cases of high multicollinearity, Lasso can select one of the correlated features and set the coefficients of the others to zero, which can help in feature selection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f824a180-ff27-4f8c-a09a-95c090efdbee",
   "metadata": {},
   "source": [
    "#### Q8. How do you choose the optimal value of the regularization parameter (lambda) in Lasso Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf242e6-c10a-4c1e-a85d-5b4000a2a3f4",
   "metadata": {},
   "source": [
    "The optimal lambda value is chosen through techniques like cross-validation. Cross-validation involves splitting the data into training and validation sets multiple times, training the model with different lambda values, and selecting the one that minimizes prediction error on the validation set. Cross-validation helps strike a balance between model complexity and predictive performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
